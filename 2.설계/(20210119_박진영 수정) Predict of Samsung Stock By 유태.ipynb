{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import yfinance as yf # yahoo finance API    # pip install yfinance\n",
    "import investpy # investing.com API          # pip install investpy\n",
    "from pykrx import stock # krx API           # pip instasll pykrx\n",
    "import talib as ta # 기술적 분석 (보조지표)\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 start_date, end_date\n",
    "'''\n",
    "start_date=input('YYYY-MM-DD 형식을 지켜 입력해주세요 ex) 2018-01-01 : ')\n",
    "end_date=input('YYYY-MM-DD 형식을 지켜 입력해주세요 ex) 2020-10-13 : ')\n",
    "'''\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2020-12-31'\n",
    "train_date = '2018-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집기간 입력\n",
    "# yahoo finance 양식, ex) yyyy-mm-dd\n",
    "#start_date = '2018-01-01'\n",
    "#end_date = '2020-10-13'\n",
    "\n",
    "# investing.com 양식, ex) dd/mm/yyyy\n",
    "start_date_ = start_date[8:] + '/' + start_date[5:7] + '/' + start_date[:4]\n",
    "end_date_ = end_date[8:] + '/' + end_date[5:7] + '/' + end_date[:4]\n",
    "\n",
    "# krx 양식 ex) yyyymmdd\n",
    "start_date__ = start_date[0:4] + start_date[5:7] + start_date[8:10]\n",
    "end_date__ = end_date[0:4] + end_date[5:7] + end_date[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# 주요 3개국 대비 원 환율\n",
    "\n",
    "# 달러/원\n",
    "exchange_rate_usd_ = investpy.get_currency_cross_historical_data(currency_cross='USD/KRW', from_date=start_date_, to_date=end_date_)\n",
    "exchange_rate_usd_.columns = ['exchange_rate_usd_Open', 'exchange_rate_usd_High', 'exchange_rate_usd_Low', 'exchange_rate_usd_Close', 'exchange_rate_usd_Currency']\n",
    "exchange_rate_usd_ = exchange_rate_usd_.drop(['exchange_rate_usd_Open','exchange_rate_usd_High','exchange_rate_usd_Low','exchange_rate_usd_Currency'], axis=1)\n",
    "\n",
    "# NASDAQ\n",
    "nasdaq_ = yf.download(\"^IXIC\", start=start_date, end=end_date)\n",
    "nasdaq_.columns = ['nasdaq_Open','nasdaq_High','nasdaq_Low','nasdaq_Close','nasdaq_Adj Close','nasdaq_Volume']\n",
    "nasdaq_ = nasdaq_.drop(['nasdaq_Open','nasdaq_High','nasdaq_Low','nasdaq_Adj Close','nasdaq_Volume'], axis=1)\n",
    "\n",
    "# Russell 2000\n",
    "russell_2000_ = yf.download(\"^RUT\", start=start_date, end=end_date)\n",
    "russell_2000_.columns = ['russell_2000_Open','russell_2000_High','russell_2000_Low','russell_2000_Close','russell_2000_Adj Close','russell_2000_Volume']\n",
    "russell_2000_ = russell_2000_.drop(['russell_2000_Open','russell_2000_High','russell_2000_Low','russell_2000_Adj Close','russell_2000_Volume'], axis=1)\n",
    "\n",
    "# 삼성 차트 데이터\n",
    "sam_ = stock.get_market_ohlcv_by_date(start_date__, end_date__, \"005930\")\n",
    "sam_.columns = ['Open','High','Low','Close','Volume']\n",
    "model_samsung = sam_.copy()\n",
    "\n",
    "# 3) MACD 이동평균수렴확산 (단기(EMA12)와 장기(EMA26) EMA로 모멘텀을 추정)\n",
    "macd, macdsignal9, macdhist = ta.MACD(model_samsung.Close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "model_samsung['macd'] = macd\n",
    "model_samsung['macdsignal9'] = macdsignal9\n",
    "model_samsung['macdhist'] = macdhist\n",
    "\n",
    "# 2) 볼린저밴드 (주가의 이동평균선을 중심으로 표준편차 범위를 표시)\n",
    "ubb, mbb, lbb = ta.BBANDS(model_samsung.Close, 20, 2)\n",
    "model_samsung['ubb'] = ubb\n",
    "model_samsung['mbb'] = mbb\n",
    "model_samsung['lbb'] = lbb\n",
    "\n",
    "# 1) 이평선(SMA, EMA, WMA) (w = 5,10,15,20,30,60,120)\n",
    "model_samsung['ma_5'] = ta.SMA(model_samsung.Close, timeperiod=5)\n",
    "model_samsung['ma_10'] = ta.SMA(model_samsung.Close, timeperiod=10)\n",
    "model_samsung['ma_15'] = ta.SMA(model_samsung.Close, timeperiod=15)\n",
    "model_samsung['ma_20'] = ta.SMA(model_samsung.Close, timeperiod=20)\n",
    "model_samsung['ma_30'] = ta.SMA(model_samsung.Close, timeperiod=30)\n",
    "model_samsung['ma_60'] = ta.SMA(model_samsung.Close, timeperiod=60)\n",
    "model_samsung['ma_120'] = ta.SMA(model_samsung.Close, timeperiod=120)\n",
    "\n",
    "MSCI_KR = fdr.DataReader('156080', start_date,end_date) #MSCI KOREA\n",
    "MSCI_KR = MSCI_KR.drop(['Open','High','Low', 'Change','Volume'], axis=1) \n",
    "MSCI_KR.columns = ['MSCI_KR']\n",
    "\n",
    "# SOX 지수\n",
    "SOX = yf.download(\"^SOX\", start=start_date, end=end_date)\n",
    "SOX.columns = ['SOXX_Open','SOXX_High','SOXX_Low','SOXX_Close','SOXX_Adj Close','SOXX_Volume']\n",
    "SOX = SOX.drop(['SOXX_Open','SOXX_High','SOXX_Low','SOXX_Adj Close','SOXX_Volume'], axis=1)\n",
    "\n",
    "# 미국 국채 수익률 (5년)\n",
    "treasury_5y_ = yf.download(\"^FVX\", start=start_date, end=end_date)\n",
    "treasury_5y_.columns = ['treasury_5y_Open','treasury_5y_High','treasury_5y_Low','treasury_5y_Close','treasury_5y_Adj Close','treasury_5y_Volume']\n",
    "treasury_5y_ = treasury_5y_.drop(['treasury_5y_Open','treasury_5y_High','treasury_5y_Low','treasury_5y_Adj Close','treasury_5y_Volume'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_samsung['exchange_rate_usd'] = exchange_rate_usd_\n",
    "model_samsung['nasdaq'] = nasdaq_\n",
    "model_samsung['russell_2000'] = russell_2000_\n",
    "model_samsung['MSCI_KR'] = MSCI_KR\n",
    "model_samsung['SOX'] = SOX\n",
    "model_samsung['treasury_5y'] = treasury_5y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsignal9</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>ubb</th>\n",
       "      <th>mbb</th>\n",
       "      <th>...</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>ma_60</th>\n",
       "      <th>ma_120</th>\n",
       "      <th>exchange_rate_usd</th>\n",
       "      <th>nasdaq</th>\n",
       "      <th>russell_2000</th>\n",
       "      <th>MSCI_KR</th>\n",
       "      <th>SOX</th>\n",
       "      <th>treasury_5y</th>\n",
       "      <th>Labeling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>27900</td>\n",
       "      <td>28180</td>\n",
       "      <td>27540</td>\n",
       "      <td>27800</td>\n",
       "      <td>315924</td>\n",
       "      <td>514.972445</td>\n",
       "      <td>386.143049</td>\n",
       "      <td>128.829397</td>\n",
       "      <td>27568.172985</td>\n",
       "      <td>26146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25918.000000</td>\n",
       "      <td>24566.000000</td>\n",
       "      <td>22634.000000</td>\n",
       "      <td>1130.15</td>\n",
       "      <td>3046.360107</td>\n",
       "      <td>816.880005</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>413.390015</td>\n",
       "      <td>0.811</td>\n",
       "      <td>28200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-02</th>\n",
       "      <td>28200</td>\n",
       "      <td>28360</td>\n",
       "      <td>27980</td>\n",
       "      <td>28200</td>\n",
       "      <td>368585</td>\n",
       "      <td>619.193325</td>\n",
       "      <td>432.753104</td>\n",
       "      <td>186.440222</td>\n",
       "      <td>27933.771899</td>\n",
       "      <td>26257.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26018.000000</td>\n",
       "      <td>24680.666667</td>\n",
       "      <td>22707.333333</td>\n",
       "      <td>1130.20</td>\n",
       "      <td>3059.850098</td>\n",
       "      <td>818.599976</td>\n",
       "      <td>10718.0</td>\n",
       "      <td>416.809998</td>\n",
       "      <td>0.819</td>\n",
       "      <td>28020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-03</th>\n",
       "      <td>28040</td>\n",
       "      <td>28200</td>\n",
       "      <td>27960</td>\n",
       "      <td>28020</td>\n",
       "      <td>206721</td>\n",
       "      <td>679.432553</td>\n",
       "      <td>482.088994</td>\n",
       "      <td>197.343559</td>\n",
       "      <td>28160.532041</td>\n",
       "      <td>26323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26107.333333</td>\n",
       "      <td>24789.666667</td>\n",
       "      <td>22776.666667</td>\n",
       "      <td>1131.25</td>\n",
       "      <td>3024.300049</td>\n",
       "      <td>806.590027</td>\n",
       "      <td>10655.0</td>\n",
       "      <td>406.489990</td>\n",
       "      <td>0.817</td>\n",
       "      <td>27200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-04</th>\n",
       "      <td>27499</td>\n",
       "      <td>27960</td>\n",
       "      <td>26980</td>\n",
       "      <td>27200</td>\n",
       "      <td>410013</td>\n",
       "      <td>653.472602</td>\n",
       "      <td>516.365715</td>\n",
       "      <td>137.106887</td>\n",
       "      <td>28239.902768</td>\n",
       "      <td>26363.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26186.000000</td>\n",
       "      <td>24878.666667</td>\n",
       "      <td>22847.500000</td>\n",
       "      <td>1135.85</td>\n",
       "      <td>2956.340088</td>\n",
       "      <td>791.840027</td>\n",
       "      <td>10578.0</td>\n",
       "      <td>397.940002</td>\n",
       "      <td>0.784</td>\n",
       "      <td>26840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-07</th>\n",
       "      <td>26840</td>\n",
       "      <td>27060</td>\n",
       "      <td>26500</td>\n",
       "      <td>26840</td>\n",
       "      <td>378463</td>\n",
       "      <td>596.968679</td>\n",
       "      <td>532.486308</td>\n",
       "      <td>64.482371</td>\n",
       "      <td>28260.857895</td>\n",
       "      <td>26375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26242.000000</td>\n",
       "      <td>24962.000000</td>\n",
       "      <td>22907.333333</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>2957.760010</td>\n",
       "      <td>793.809998</td>\n",
       "      <td>10377.0</td>\n",
       "      <td>396.920013</td>\n",
       "      <td>0.782</td>\n",
       "      <td>26820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>73100</td>\n",
       "      <td>73400</td>\n",
       "      <td>72000</td>\n",
       "      <td>73000</td>\n",
       "      <td>20367355</td>\n",
       "      <td>2549.262043</td>\n",
       "      <td>2740.192720</td>\n",
       "      <td>-190.930676</td>\n",
       "      <td>76325.510422</td>\n",
       "      <td>71060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68683.333333</td>\n",
       "      <td>64025.000000</td>\n",
       "      <td>60196.666667</td>\n",
       "      <td>1102.55</td>\n",
       "      <td>12742.519531</td>\n",
       "      <td>1970.329956</td>\n",
       "      <td>17820.0</td>\n",
       "      <td>2747.290039</td>\n",
       "      <td>0.383</td>\n",
       "      <td>72300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>72500</td>\n",
       "      <td>73200</td>\n",
       "      <td>72100</td>\n",
       "      <td>72300</td>\n",
       "      <td>16304910</td>\n",
       "      <td>2352.270424</td>\n",
       "      <td>2662.608261</td>\n",
       "      <td>-310.337836</td>\n",
       "      <td>76346.045886</td>\n",
       "      <td>71290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69086.666667</td>\n",
       "      <td>64253.333333</td>\n",
       "      <td>60359.166667</td>\n",
       "      <td>1109.72</td>\n",
       "      <td>12807.919922</td>\n",
       "      <td>1989.880005</td>\n",
       "      <td>17595.0</td>\n",
       "      <td>2743.969971</td>\n",
       "      <td>0.364</td>\n",
       "      <td>73900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>72400</td>\n",
       "      <td>74000</td>\n",
       "      <td>72300</td>\n",
       "      <td>73900</td>\n",
       "      <td>19411326</td>\n",
       "      <td>2298.761089</td>\n",
       "      <td>2589.838826</td>\n",
       "      <td>-291.077738</td>\n",
       "      <td>76344.765453</td>\n",
       "      <td>71655.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69506.666667</td>\n",
       "      <td>64521.666667</td>\n",
       "      <td>60536.666667</td>\n",
       "      <td>1106.65</td>\n",
       "      <td>12771.110352</td>\n",
       "      <td>2007.099976</td>\n",
       "      <td>17875.0</td>\n",
       "      <td>2723.530029</td>\n",
       "      <td>0.377</td>\n",
       "      <td>77800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>79000</td>\n",
       "      <td>80100</td>\n",
       "      <td>78200</td>\n",
       "      <td>78700</td>\n",
       "      <td>40085044</td>\n",
       "      <td>2774.958927</td>\n",
       "      <td>2619.168990</td>\n",
       "      <td>155.789937</td>\n",
       "      <td>78173.853196</td>\n",
       "      <td>72670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70583.333333</td>\n",
       "      <td>65195.000000</td>\n",
       "      <td>60953.333333</td>\n",
       "      <td>1095.60</td>\n",
       "      <td>12899.419922</td>\n",
       "      <td>1996.250000</td>\n",
       "      <td>18245.0</td>\n",
       "      <td>2744.300049</td>\n",
       "      <td>0.364</td>\n",
       "      <td>78300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>78800</td>\n",
       "      <td>78900</td>\n",
       "      <td>77300</td>\n",
       "      <td>78300</td>\n",
       "      <td>30339449</td>\n",
       "      <td>2894.138437</td>\n",
       "      <td>2674.162879</td>\n",
       "      <td>219.975558</td>\n",
       "      <td>78556.411217</td>\n",
       "      <td>73250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70983.333333</td>\n",
       "      <td>65530.000000</td>\n",
       "      <td>61147.500000</td>\n",
       "      <td>1090.97</td>\n",
       "      <td>12850.219727</td>\n",
       "      <td>1959.359985</td>\n",
       "      <td>18650.0</td>\n",
       "      <td>2738.050049</td>\n",
       "      <td>0.378</td>\n",
       "      <td>81000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2049 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close    Volume         macd  macdsignal9  \\\n",
       "날짜                                                                           \n",
       "2012-04-30  27900  28180  27540  27800    315924   514.972445   386.143049   \n",
       "2012-05-02  28200  28360  27980  28200    368585   619.193325   432.753104   \n",
       "2012-05-03  28040  28200  27960  28020    206721   679.432553   482.088994   \n",
       "2012-05-04  27499  27960  26980  27200    410013   653.472602   516.365715   \n",
       "2012-05-07  26840  27060  26500  26840    378463   596.968679   532.486308   \n",
       "...           ...    ...    ...    ...       ...          ...          ...   \n",
       "2020-12-21  73100  73400  72000  73000  20367355  2549.262043  2740.192720   \n",
       "2020-12-22  72500  73200  72100  72300  16304910  2352.270424  2662.608261   \n",
       "2020-12-23  72400  74000  72300  73900  19411326  2298.761089  2589.838826   \n",
       "2020-12-28  79000  80100  78200  78700  40085044  2774.958927  2619.168990   \n",
       "2020-12-29  78800  78900  77300  78300  30339449  2894.138437  2674.162879   \n",
       "\n",
       "              macdhist           ubb      mbb  ...         ma_30  \\\n",
       "날짜                                             ...                 \n",
       "2012-04-30  128.829397  27568.172985  26146.0  ...  25918.000000   \n",
       "2012-05-02  186.440222  27933.771899  26257.0  ...  26018.000000   \n",
       "2012-05-03  197.343559  28160.532041  26323.0  ...  26107.333333   \n",
       "2012-05-04  137.106887  28239.902768  26363.0  ...  26186.000000   \n",
       "2012-05-07   64.482371  28260.857895  26375.0  ...  26242.000000   \n",
       "...                ...           ...      ...  ...           ...   \n",
       "2020-12-21 -190.930676  76325.510422  71060.0  ...  68683.333333   \n",
       "2020-12-22 -310.337836  76346.045886  71290.0  ...  69086.666667   \n",
       "2020-12-23 -291.077738  76344.765453  71655.0  ...  69506.666667   \n",
       "2020-12-28  155.789937  78173.853196  72670.0  ...  70583.333333   \n",
       "2020-12-29  219.975558  78556.411217  73250.0  ...  70983.333333   \n",
       "\n",
       "                   ma_60        ma_120  exchange_rate_usd        nasdaq  \\\n",
       "날짜                                                                        \n",
       "2012-04-30  24566.000000  22634.000000            1130.15   3046.360107   \n",
       "2012-05-02  24680.666667  22707.333333            1130.20   3059.850098   \n",
       "2012-05-03  24789.666667  22776.666667            1131.25   3024.300049   \n",
       "2012-05-04  24878.666667  22847.500000            1135.85   2956.340088   \n",
       "2012-05-07  24962.000000  22907.333333            1138.50   2957.760010   \n",
       "...                  ...           ...                ...           ...   \n",
       "2020-12-21  64025.000000  60196.666667            1102.55  12742.519531   \n",
       "2020-12-22  64253.333333  60359.166667            1109.72  12807.919922   \n",
       "2020-12-23  64521.666667  60536.666667            1106.65  12771.110352   \n",
       "2020-12-28  65195.000000  60953.333333            1095.60  12899.419922   \n",
       "2020-12-29  65530.000000  61147.500000            1090.97  12850.219727   \n",
       "\n",
       "            russell_2000  MSCI_KR          SOX  treasury_5y  Labeling  \n",
       "날짜                                                                     \n",
       "2012-04-30    816.880005  10609.0   413.390015        0.811   28200.0  \n",
       "2012-05-02    818.599976  10718.0   416.809998        0.819   28020.0  \n",
       "2012-05-03    806.590027  10655.0   406.489990        0.817   27200.0  \n",
       "2012-05-04    791.840027  10578.0   397.940002        0.784   26840.0  \n",
       "2012-05-07    793.809998  10377.0   396.920013        0.782   26820.0  \n",
       "...                  ...      ...          ...          ...       ...  \n",
       "2020-12-21   1970.329956  17820.0  2747.290039        0.383   72300.0  \n",
       "2020-12-22   1989.880005  17595.0  2743.969971        0.364   73900.0  \n",
       "2020-12-23   2007.099976  17875.0  2723.530029        0.377   77800.0  \n",
       "2020-12-28   1996.250000  18245.0  2744.300049        0.364   78300.0  \n",
       "2020-12-29   1959.359985  18650.0  2738.050049        0.378   81000.0  \n",
       "\n",
       "[2049 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samsung 모델\n",
    "model_samsung['Labeling'] = model_samsung['Close'].shift(-1)\n",
    "model_samsung = model_samsung.dropna() # 결측치가 있는 행 제거\n",
    "model_samsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2049 entries, 2012-04-30 to 2020-12-29\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Open               2049 non-null   int32  \n",
      " 1   High               2049 non-null   int32  \n",
      " 2   Low                2049 non-null   int32  \n",
      " 3   Close              2049 non-null   int32  \n",
      " 4   Volume             2049 non-null   int32  \n",
      " 5   macd               2049 non-null   float64\n",
      " 6   macdsignal9        2049 non-null   float64\n",
      " 7   macdhist           2049 non-null   float64\n",
      " 8   ubb                2049 non-null   float64\n",
      " 9   mbb                2049 non-null   float64\n",
      " 10  lbb                2049 non-null   float64\n",
      " 11  ma_5               2049 non-null   float64\n",
      " 12  ma_10              2049 non-null   float64\n",
      " 13  ma_15              2049 non-null   float64\n",
      " 14  ma_20              2049 non-null   float64\n",
      " 15  ma_30              2049 non-null   float64\n",
      " 16  ma_60              2049 non-null   float64\n",
      " 17  ma_120             2049 non-null   float64\n",
      " 18  exchange_rate_usd  2049 non-null   float64\n",
      " 19  nasdaq             2049 non-null   float64\n",
      " 20  russell_2000       2049 non-null   float64\n",
      " 21  MSCI_KR            2049 non-null   float64\n",
      " 22  SOX                2049 non-null   float64\n",
      " 23  treasury_5y        2049 non-null   float64\n",
      " 24  Labeling           2049 non-null   float64\n",
      "dtypes: float64(20), int32(5)\n",
      "memory usage: 376.2 KB\n"
     ]
    }
   ],
   "source": [
    "model_samsung.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samsung 모델\n",
    "'''\n",
    "lst_label = ['a']\n",
    "for i in range(len(model_samsung)-1):\n",
    "    if model_samsung.iloc[i+1]['Close'] == model_samsung.iloc[i]['Close']:\n",
    "        lst_label.append(2) # 전일 주가 = 당일 주가 : 2\n",
    "    elif model_samsung.iloc[i+1]['Close'] > model_samsung.iloc[i]['Close']:\n",
    "        lst_label.append(0) # 전일 주가 < 당일 주가 : 0\n",
    "    else:\n",
    "        lst_label.append(1) # 전일 주가 > 당일 주가 : 1\n",
    "model_samsung['Labeling'] = lst_label\n",
    "model_samsung = model_samsung.drop(model_samsung[model_samsung['Labeling'] == 'a'].index) # 첫 행 삭제\n",
    "model_samsung = model_samsung.drop(model_samsung[model_samsung['Labeling'] == 2].index) # 전일 주가 = 당일 주가인 행 삭제\n",
    "model_samsung['Labeling'] = model_samsung['Labeling'].astype(\"category\")\n",
    "model_samsung = model_samsung.dropna() # 결측치가 있는 행 제거\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049, 21)\n",
      "(1575, 21)\n"
     ]
    }
   ],
   "source": [
    "#4 test, train 나누기\n",
    "df_scaled = model_samsung.copy()\n",
    "df_scaled.drop(['Open', 'High', 'Low', 'Volume'], axis=1, inplace=True)\n",
    "#df_scaled = df_scaled[['Close','macd','macdhist','exchange_rate_usd','ubb','MSCI_KR','treasury_5y','macdsignal9','nasdaq', 'Labeling']]\n",
    "train_set = df_scaled[:train_date].values\n",
    "\n",
    "print(df_scaled.shape)\n",
    "print(train_set.shape)\n",
    "#print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = 5\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(time_seq, train_set.shape[0]):\n",
    "    X_train.append(train_set[i-time_seq:i, 0:train_set.shape[1]-1])\n",
    "    y_train.append(train_set[i, train_set.shape[1]-1:])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "#sc2 = StandardScaler()\n",
    "sc2 = MinMaxScaler()\n",
    "for i in range(X_train.shape[1]):\n",
    "    scalers[i] = MinMaxScaler()\n",
    "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "    \n",
    "y_train = sc2.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1570, 5, 20)\n",
      "(1570, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(train_set.shape[0], df_scaled.shape[0]):\n",
    "    X_test.append(df_scaled.values[i-time_seq:i, 0:train_set.shape[1]-1])\n",
    "    y_test.append(df_scaled.values[i, train_set.shape[1]-1:])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
    "\n",
    "y_test = sc2.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00212: early stopping\n"
     ]
    }
   ],
   "source": [
    "#7 딥러닝에 적용하기\n",
    "from keras.callbacks import EarlyStopping\n",
    "# LSTM 모델 만들기\n",
    "model = Sequential()\n",
    "# LSTM 레이어를 쌓아올릴 때는 return_sequences 를 True로 설정한다\n",
    "# LSTM 을 사용하기 위해서는 3차원 데이터가 필요(batch_size, timesteps, input_dim)\n",
    "model.add(LSTM(60, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(30, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=200, verbose=1)\n",
    "history = model.fit(X_train, y_train, batch_size=50, epochs=300, validation_data=(X_test, y_test), verbose=0, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.001, Test: 0.016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_loss, test_loss))\n",
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (474,5,1) (474,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e0b285b16483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (474,5,1) (474,1) "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691948926795429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set의 평균을 예측값으로 했을 때의 오차\n",
    "mu = y_train.mean()\n",
    "np.sqrt(np.mean((y_test - mu) ** 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 확인\n",
    "train = df_scaled[:train_date][['Labeling']]\n",
    "valid = df_scaled[train_date:][['Labeling']]\n",
    "valid['Predictions'] = sc2.inverse_transform(predictions)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('prediction', fontsize=18)\n",
    "#plt.plot(train)\n",
    "plt.plot(valid['Labeling'])\n",
    "plt.plot(valid['Predictions'])\n",
    "plt.legend(['Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_1 = pd.to_datetime(train_date)\n",
    "view_date = date_1 + datetime.timedelta(days=30)\n",
    "view_date = str(view_date)\n",
    "view_date = view_date[:10]\n",
    "view_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부분 확대\n",
    "valid = df_scaled[train_date:][['Labeling']]\n",
    "valid['Predictions'] = sc2.inverse_transform(predictions)\n",
    "\n",
    "valid = valid[train_date:view_date]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('prediction', fontsize=18)\n",
    "#plt.plot(train)\n",
    "plt.plot(valid['Labeling'])\n",
    "plt.plot(valid['Predictions'])\n",
    "plt.legend(['Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def xgBoostGridSearch(trainTuple, validTuple, paramDic, colNmList, obj='reg:squarederror') :\n",
    "    parameters = {\n",
    "        'booster' :['gbtree'],\n",
    "        'learning_rate':paramDic['learning_rate'],\n",
    "        'n_estimators':paramDic['n_estimators'],\n",
    "        'max_depth':paramDic['max_depth'],\n",
    "        'gamma':paramDic['gamma'],\n",
    "        'random_state':paramDic['random_state'],\n",
    "        #'early_stoppings':paramDic['early_stoppings']\n",
    "    }\n",
    "    cv=TimeSeriesSplit(n_splits=5)\n",
    "    #eval_set = [trainTuple, validTuple]\n",
    "    # objective : 목적함수. 이 함수를 통해 나온 값이 최소화되는 방향으로 학습된다.\n",
    "    # binary:logistic : 이항 분류(binary class)에 사용\n",
    "    # multi:softmax / multi:softprob : 다항 분류(multi class)에 사용.\n",
    "    if obj == 'binary:logistic' :\n",
    "        model = xgb.XGBClassifier(objective=obj)\n",
    "    else :\n",
    "        model = xgb.XGBRegressor(objective=obj)\n",
    "    \n",
    "    clf = GridSearchCV(model, parameters, cv=cv)\n",
    "    \n",
    "    dtrain = pd.DataFrame(trainTuple[0], columns=colNmList)\n",
    "    clf.fit(dtrain, trainTuple[1])\n",
    "    print(f'Best params : {clf.best_params_}')\n",
    "    print(f'Best validation score = {clf.best_score_}')\n",
    "    return clf\n",
    "\n",
    "def xgBoost(clf, trainTuple, validTuple, colNmList, obj='reg:squarederror', fiGraph=True) :\n",
    "    dtrain = pd.DataFrame(trainTuple[0], columns=colNmList)\n",
    "    dvalid = pd.DataFrame(validTuple[0], columns=colNmList)\n",
    "    #eval_set = [(dtrain, trainTuple[1]), (dvalid, validTuple[1])]\n",
    "    eval_set = [(dvalid, validTuple[1])]\n",
    "    \n",
    "    if obj == 'binary:logistic' :\n",
    "        model = xgb.XGBClassifier(**clf.best_params_, objective=obj)\n",
    "    else :\n",
    "        model = xgb.XGBRegressor(**clf.best_params_, objective=obj)\n",
    "    \n",
    "    model.fit(dtrain, trainTuple[1], eval_set=eval_set, verbose=False)\n",
    "    model.get_booster().get_score(importance_type='weight')\n",
    "    \n",
    "    if fiGraph :\n",
    "        plot_importance(model)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def pred(model, testTuple, df_scaled, colNmList, scaler, colNm='Labeling') :\n",
    "    dtrain = pd.DataFrame(trainTuple[0], columns=colNmList)\n",
    "    dtest = pd.DataFrame(testTuple[0], columns=colNmList)\n",
    "    y_pred = model.predict(dtest)\n",
    "    print(f'mean_squared_error = {mean_squared_error(testTuple[1], y_pred)}')\n",
    "\n",
    "    # 예측값과 실제값 그려보기\n",
    "    # 그래프로 확인\n",
    "    train = df_scaled[:train_date][['Labeling']]\n",
    "    valid = df_scaled[train_date:][['Labeling']]\n",
    "    valid['Predictions'] = scaler.inverse_transform(np.reshape(y_pred, (y_pred.shape[0], 1)))\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.title('Model')\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('prediction', fontsize=18)\n",
    "    #plt.plot(train)\n",
    "    plt.plot(valid['Labeling'])\n",
    "    plt.plot(valid['Predictions'])\n",
    "    plt.legend(['Val', 'Predictions'], loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = list(df_scaled.columns)\n",
    "colList.remove('Labeling')\n",
    "colList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "import plotly as py\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "X_train_ = []\n",
    "y_train_ = []\n",
    "for i in range(0, train_set.shape[0]):\n",
    "    X_train_.append(train_set[i, 0:train_set.shape[1]-1])\n",
    "    y_train_.append(train_set[i, train_set.shape[1]-1:])\n",
    "X_train_, y_train_ = np.array(X_train_), np.array(y_train_)\n",
    "\n",
    "sc1_ = MinMaxScaler()\n",
    "sc2_ = MinMaxScaler()\n",
    "X_train_ = sc1_.fit_transform(X_train_)  \n",
    "y_train_ = sc2_.fit_transform(y_train_)\n",
    "\n",
    "X_test_ = []\n",
    "y_test_ = []\n",
    "for i in range(train_set.shape[0], df_scaled.shape[0]):\n",
    "    X_test_.append(df_scaled.values[i, 0:train_set.shape[1]-1])\n",
    "    y_test_.append(df_scaled.values[i, train_set.shape[1]-1:])\n",
    "X_test_, y_test_ = np.array(X_test_), np.array(y_test_)\n",
    "\n",
    "X_test_ = sc1_.transform(X_test_)  \n",
    "y_test_ = sc2_.transform(y_test_)\n",
    "\n",
    "trainTuple = (X_train_, y_train_)\n",
    "testTuple = (X_test_, y_test_)\n",
    "validTuple = testTuple\n",
    "\n",
    "paramDic = {}\n",
    "paramDic['n_estimators'] = [100, 200]\n",
    "paramDic['max_depth'] = [5, 8]\n",
    "paramDic['gamma'] = [0]\n",
    "paramDic['random_state'] = [50]\n",
    "paramDic['learning_rate'] = [0.05, 0.1]\n",
    "\n",
    "clf = xgBoostGridSearch(trainTuple, validTuple, paramDic, colList)\n",
    "model = xgBoost(clf, trainTuple, validTuple, colList)\n",
    "\n",
    "pred(model, testTuple, df_scaled, colList, sc2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
