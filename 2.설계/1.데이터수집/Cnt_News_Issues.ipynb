{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnt_issues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1uwiMhTbkJT"
      },
      "source": [
        "# 뉴스 크롤링 자연어 처리 함수\r\n",
        "* 입력 종목코드로 NAVER 뉴스 크롤링\r\n",
        "* 해당 뉴스 제목들 중 부정적인 단어LIST가 들어있는 DF행 제거 후 개수 반환 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp_spREg-JgQ"
      },
      "source": [
        "!pip install Selenium\r\n",
        "!apt-get update # to update ubuntu to correctly run apt install\r\n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t_E1TDS-Yq2"
      },
      "source": [
        "import os\r\n",
        "import time\r\n",
        "import re\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import requests\r\n",
        "\r\n",
        "from selenium import webdriver\r\n",
        "from selenium.webdriver.chrome.options import Options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVFnE-fwUBC-"
      },
      "source": [
        "#마지막 페이지 번호\r\n",
        "def getLastPageNum(soup) :\r\n",
        "    return int(soup.find(\"table\", class_=\"Nnavi\").find(\"td\", class_=\"pgRR\").find(\"a\").get(\"href\").split(\"&\")[1].split(\"=\")[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DPqzLFG-j6E"
      },
      "source": [
        "#뉴스 데이터 가져오기(관련기사는 제거)\r\n",
        "def getPageNewsData(news_url, page) :\r\n",
        "    url = news_url + \"&page=\" + str(page)\r\n",
        "    response = requests.get(url)\r\n",
        "    response.encoding = 'euc-kr' #한글깨짐방지\r\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\r\n",
        "    \r\n",
        "    table = soup.find('table')\r\n",
        "    rlist = table.find_all('tr', class_=\"relation_lst\")\r\n",
        "    for tr in rlist :\r\n",
        "        tr.decompose()\r\n",
        "\r\n",
        "    df = pd.read_html(str(table), header=0)[0].dropna()\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spRskmxSdYE"
      },
      "source": [
        "def GetIssueCnt(code, startDate, bad_word) :\r\n",
        "  #기사 가져오기\r\n",
        "  news_url = 'https://finance.naver.com/item/news_news.nhn?code='+code # 뉴스 기사\r\n",
        "  response = requests.get(news_url)\r\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\r\n",
        "\r\n",
        "  last_page = getLastPageNum(soup)\r\n",
        "  last_index = last_page+1\r\n",
        "\r\n",
        "  news_df = getPageNewsData(news_url, 1).dropna()\r\n",
        "  for i in range(2, last_index) :\r\n",
        "      tmp_df = getPageNewsData(news_url, i)\r\n",
        "      add_df = tmp_df[tmp_df['날짜'] > startDate]\r\n",
        "      news_df = pd.concat([news_df, add_df], ignore_index=True)\r\n",
        "      if len(add_df) < len(tmp_df) : \r\n",
        "          break\r\n",
        "\r\n",
        "  news_df = news_df.drop_duplicates()\r\n",
        "  news_df = news_df.drop(['정보제공', '날짜'], axis=1).rename({'제목':'subject'}, axis='columns')\r\n",
        "\r\n",
        "  list = []\r\n",
        "  for i in range(0, len(news_df)) :\r\n",
        "      index = news_df[\"subject\"].index[i]\r\n",
        "      list.append(\" \".join(clean(news_df[\"subject\"][index])))\r\n",
        "      #list.append(\" \".join(news_df[\"subject\"][index]))\r\n",
        "  df= pd.DataFrame(list)\r\n",
        "  df.columns = [\"subject\"]\r\n",
        "  df['subject'] = df['subject'].astype(str)\r\n",
        "  df = df[~df['subject'].str.contains('|'.join(bad_word))] #bad_word 에 포함된 행을 제거 \r\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwdFDlSmU2DP"
      },
      "source": [
        "def clean(sub) :\r\n",
        "    text = re.sub(\"[^ㄱ-ㅣ가-힣]\", \" \", sub)\r\n",
        "    text2 = text.split()\r\n",
        "    text3 = [w for w in text2 if not w in stopwords]\r\n",
        "    return text3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "JbNjzXgp-t8A",
        "outputId": "4aca1007-98fb-4634-a131-633030f23ef6"
      },
      "source": [
        "company = input(\"회사명 or 종목명 입력: 씨젠 디폴트 \")\r\n",
        "#code = convert_to_code(company)\r\n",
        "code = '096530'\r\n",
        "\r\n",
        "if code is None or code == '' :\r\n",
        "    print(\"코드입력 없으면 씨젠 096530 검색\")\r\n",
        "    code = '096530'\r\n",
        "    \r\n",
        "startDate = input(\"뉴스 기사 마지막 날짜: \")\r\n",
        "\r\n",
        "if startDate is None or startDate == '' :\r\n",
        "    print(\"날짜 입력이 없어 Default(2020.06.30)를 수행합니다.\")\r\n",
        "    startDate = '2020.06.30'\r\n",
        "\r\n",
        "#부정적인 단어는 빼고 이슈 기사의 갯수를 가져온다.\r\n",
        "bad_word = ['하락세', '사기', '실망', '적발','부진','약세', '고소' ,'신고', '우려' ,'불능' ,'부실' ,'희박', '연기']\r\n",
        "stopwords = [company] #입력받은 회사명은 불용어 제거 -> 딱히 필요없음\r\n",
        "df =GetIssueCnt(code, startDate, bad_word)\r\n",
        "df\r\n",
        "#len(df) # 뉴스제목에 부정적인 단어가 들어간 기사를 뺀 개수\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "회사명 or 종목명 입력: 씨젠 디폴트 \n",
            "뉴스 기사 마지막 날짜: \n",
            "날짜 입력이 없어 Default(2020.06.30)를 수행합니다.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>씨젠 임직원 명에서 명으로 일자리 유공 표창 수상</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>천종윤 씨젠 대표 보건의료기술 진흥 대통령 표창 수상</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>겨울 보너스 배당주 막차 타볼까 씨젠 주당 원 배당</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>씨젠 제조 구매 총괄 부사장에 이기선 대림산업 영입</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>씨젠 타액 진단 코로나 진단 키트 개발 기대 하나금투</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>씨젠 개인 투자자 관심 집중 주가</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>일 기관 코스닥에서 에스엠 씨젠</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>주식 초고수는 지금 셀트리온 사자 위 씨젠은 집중매도</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>씨젠 검색 상위 랭킹 주가</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>씨젠 주가 만 원 전일대비</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>190 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           subject\n",
              "0      씨젠 임직원 명에서 명으로 일자리 유공 표창 수상\n",
              "1    천종윤 씨젠 대표 보건의료기술 진흥 대통령 표창 수상\n",
              "2     겨울 보너스 배당주 막차 타볼까 씨젠 주당 원 배당\n",
              "3     씨젠 제조 구매 총괄 부사장에 이기선 대림산업 영입\n",
              "4    씨젠 타액 진단 코로나 진단 키트 개발 기대 하나금투\n",
              "..                             ...\n",
              "214             씨젠 개인 투자자 관심 집중 주가\n",
              "215              일 기관 코스닥에서 에스엠 씨젠\n",
              "216  주식 초고수는 지금 셀트리온 사자 위 씨젠은 집중매도\n",
              "217                 씨젠 검색 상위 랭킹 주가\n",
              "218                 씨젠 주가 만 원 전일대비\n",
              "\n",
              "[190 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}